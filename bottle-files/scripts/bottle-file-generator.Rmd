---
title: "Hakai Institute Bottle File Data Quality Report"
author: "Brett Johnson"
date: '`r date()`'
output:
 html_document:
   theme: cosmo
   code_folding: hide
   toc: true
   toc_float: true
   number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = FALSE)
library(tidyverse)
library(devtools)
library(lubridate)
library(knitr)
library(here)
library(car)
library(testthat)

# Read data (see data import script for data access code)
chl_all_cols <- read_csv(here("raw_data", "cha_all_cols.csv"), guess_max = 20000) 
nuts_all_cols <- read_csv(here("raw_data", "nuts_all_cols.csv"),
                          guess_max = 100000, 
                          col_types = cols(no2_no3_ugl = col_double(),
                                           tp = col_double())) 
poms_all_cols <- read_csv(here("raw_data", "poms_all_cols.csv"), guess_max = 20000) 


qu39_ctd <- read_csv(here("raw_data", "qu39_ctd.csv"), guess_max = 100000)

# Define common columns I want back from every discrete sample
common_columns <- c("event_pk", "date",  "collected", "hakai_id", "work_area", 
                    "site_id", "lat", "long","line_out_depth", "sampling_bout",
                    "pressure_transducer_depth")

#6 Deal with bottom issues: sometimes CTD doesn't go all the way down, and if we use target depth of discrete sample to match, there will be no match.

#7 Replace CTD surface measurements with YSI measurements

#8 Add DOC and CO2 to bottle file

#TODO: Pair closest CTD depth to bottle depths.
  # [ ] Preferentially use solo depths rather than target depths
  # [ ] If no solo depths, use target depth
#TODO: include flag columns for each variable
#TODO: Look out for cases when there is no start_dt
#TODO: break-out files by event_pk just before putting into erddap
#TODO: eventually add sensible comment columns
#TODO: Confirm missingness with OSV?


#Note: xml has to be updated with new variable names each time another variable is added
```

# Discrete Samples

The point of this script is to join discrete sample results taken from Niskn bottle with phsyical and biogeochemical parameters from paired CTD casts. 

Along the way I write various quality checks to summarize the quality of various samples.

## Chlorophyll a

```{r Chla QC, include = FALSE}
kable(chl_all_cols %>%  group_by(quality_level) %>% 
  summarize(n = n()), caption = "Table. Quality levels of chl a data" )

chl_all_cols %>% 
  group_by(work_area, quality_level) %>% 
  summarize(n_samples = n()) %>% 
  ggplot(aes(x = work_area, y = n_samples, fill = quality_level)) +
  geom_bar(stat = "identity") +
  labs(title = "Chla samples")

chl_all_cols %>% 
  group_by(work_area, chla_flag) %>% 
  summarize(n_samples = n()) %>% 
  ggplot(aes(x = work_area, y = n_samples, fill = chla_flag)) +
  geom_bar(stat = "identity")+
  labs(title = "Chla samples")
```

```{r Chl a}
chl <- chl_all_cols %>% 
  select(common_columns, filter_type, 
         chla_final, phaeo_final, chl_phaeo_quality_level = quality_level) %>% 
  filter(!filter_type %in% c('2 + 3', '20')) %>% 
  drop_na(filter_type, chla_final, phaeo_final) %>% 
  ungroup() %>% 
  filter(site_id == "QU39")

collapse_all_rows <- function(df) {
  return(coalesce(!!! as.list(df)))
}

chl_wide <- chl %>% 
  pivot_wider(names_from = c(filter_type), values_from = c(chla_final, phaeo_final)) %>% 
  group_by(event_pk, line_out_depth) %>% 
  summarise_all(collapse_all_rows) %>% 
  select(event_pk:chl_phaeo_quality_level, "chla_final_Bulk GF/F", "chla_final_GF/F") %>% 
  ungroup()

```

## Nutrients

```{r Nuts QC, include=FALSE}
kable(nuts_all_cols %>% group_by(quality_level) %>% 
  summarize(n = n()))

nuts_all_cols %>% 
  group_by(work_area, quality_level) %>% 
  summarize(n_samples = n()) %>% 
  ggplot(aes(x = work_area, y = n_samples, fill = quality_level)) +
  geom_bar(stat = "identity")+
  labs(title = "Nutrient samples")

```

```{r nuts replicates}

# The intent with this code chunk is to calculate the coeff. of variation for replicated samples. At some point we need to confirm when to throw out data based on too high of a CV.

nuts_replicates_qc <- nuts_all_cols %>% 
  select(common_columns, nh4_, no2_no3_um, no2_no3_ugl, no2_no3_units, tp, tdp,
         tn, tdn, srp, po4, sio2, po4pfilt, no3nfilt, po4punfl, no3nunfl,
         nh4nunfl, quality_level) %>% 
  group_by(event_pk, line_out_depth) %>% 
  summarise_at(c("nh4_", "no2_no3_um", "no2_no3_ugl",
           "tp", "tdp", "tn", "tdn", "srp", "po4", "sio2", "po4pfilt", "no3nfilt", "po4punfl",
           "no3nunfl", "nh4nunfl"), funs(mean(., na.rm = TRUE), sd(., na.rm = TRUE))) %>% 
  mutate(n_replicates = n(),
         nh4_cv         = (nh4__sd / nh4__mean) * 100,
         no2_no3_um_cv  = (no2_no3_um_sd / no2_no3_um_mean) * 100,
         no2_no3_ugl_cv = (no2_no3_ugl_sd / no2_no3_ugl_mean) * 100,
         tp_cv          = (tp_sd / tp_mean) * 100,
         tdp_cv         = (tdp_sd / tdp_mean) * 100,
         tn_cv          = (tn_sd / tn_mean) * 100,
         tdn_cv         = (tdn_sd / tdn_mean) * 100,
         srp_cv         = (srp_sd / srp_mean) * 100,
         po4_cv         = (po4_sd / po4_mean) * 100,
         sio2_cv        = (sio2_sd / sio2_mean) * 100,
         po4pfilt_cv    = (po4pfilt_sd / po4pfilt_mean) * 100,
         no3nfilt_cv    = (no3nfilt_sd / no3nfilt_mean) * 100,
         po4punfl_cv    = (po4punfl_sd / po4punfl_mean) * 100,
         no3nunfl_cv    = (no3nunfl_sd / no3nunfl_mean) * 100,
         nh4nunfl_cv    = (nh4nunfl_sd / nh4nunfl_mean) * 100
  ) %>% 
  filter(n_replicates > 1) %>% 
  ungroup() 

number_of_replicted_samping_events <- nrow(nuts_replicates_qc) 

# This lists the samples that have atleast one nutrient that has a CV > 10 (arbitrary)
high_cv <- nuts_replicates_qc %>% 
  select(
         nh4_cv,         
         no2_no3_um_cv,  
         no2_no3_ugl_cv, 
         tp_cv,          
         tdp_cv,         
         tn_cv,         
         tdn_cv,         
         srp_cv,         
         po4_cv,         
         sio2_cv,        
         po4pfilt_cv,    
         no3nfilt_cv,    
         po4punfl_cv,    
         no3nunfl_cv,    
         nh4nunfl_cv) %>% 
  filter_all(any_vars(. > 10))

nutty_nuts <- right_join(nuts_replicates_qc, high_cv) %>% 
  select(event_pk, line_out_depth, n_replicates: nh4nunfl_cv)

kable(nutty_nuts, caption = "Table. Nutrient sample replicates that have a coefficient of variation greater than .1")
```

```{r Nutrients}
nuts <- nuts_all_cols %>% 
  filter(site_id == "QU39") %>% 
    select(common_columns, nh4_, no2_no3_um, no2_no3_ugl,
           no2_no3_units, tp, tdp, tn, tdn, srp, po4, sio2, po4pfilt, no3nfilt, po4punfl,
           no3nunfl, nh4nunfl, quality_level)
  
mean_nuts <- nuts %>% 
  group_by(event_pk, line_out_depth, collected) %>% 
  summarise_at(c("nh4_", "no2_no3_um", "no2_no3_ugl",
           "tp", "tdp", "tn", "tdn", "srp", "po4", "sio2", "po4pfilt", "no3nfilt", "po4punfl",
           "no3nunfl", "nh4nunfl"), funs(mean(., na.rm = TRUE), sd(., na.rm = TRUE), n()))

```

## Particulate Organic Matter

```{r POMS QC, include=FALSE}
kable(poms_all_cols %>% group_by(quality_level) %>% 
  summarize(n = n()))

poms_all_cols %>% 
  group_by(work_area, quality_level) %>% 
  summarize(n_samples = n()) %>% 
  ggplot(aes(x = work_area, y = n_samples, fill = quality_level)) +
  geom_bar(stat = "identity") +
  labs(title = "POMS")
```


```{r POMS}
poms <- poms_all_cols %>% 
  filter(site_id == "QU39") %>% 
  select(common_columns, acidified, acidification_method, volume, part, screen_size, collected_poms = collected, preserved, analyzed, filter_portion, pre_weight_mg:row_flag, quality_level_poms = quality_level) %>%
  #rename(poms_date = date) %>% 
  ungroup()

```

## DOC

# Join Discrete Samples

```{r join discrete samples}

discrete_samples <- full_join(chl_wide, nuts, by = c("event_pk", 
                                                     "line_out_depth", "site_id"),
                              suffix = c("_chl", "_nuts")) %>%
  full_join(poms, by = c("event_pk", "line_out_depth", "site_id")) %>% 
  ungroup() %>% 
  mutate(year = year(date),
         month = month(date),
         day = yday(date)) %>% 
  group_by(event_pk) %>% 
  mutate(min_bottle_collection_t = min(collected_chl, collected_nuts, collected_poms, na.rm = TRUE),
         max_bottle_collection_t = max(collected_chl, collected_nuts, collected_poms, na.rm = TRUE),
         time_diff_mins = (max_bottle_collection_t - min_bottle_collection_t) / 60, 
         discrete_sample_timediff_flag = ifelse(time_diff_mins > 60, "SVC", ""),
         median_discrete_collected = median(collected_chl, collected_nuts, collected_poms, 
                                            na.rm = TRUE)) 

write_csv(discrete_samples, here::here("processed_data", "discrete_samples.csv"))
```

## Discrete Sample QC

To assess whether there are any mistakes, or inconsistencies in how the data are
joined, I calculate the difference in the time collected for each sample and 
comapre it to the median time collected for all samples.

```{r Discrete samples QC}
#create minimal discrete samples data frame to qc easier
min_ds <- discrete_samples %>%  
  select(event_pk, collected_poms, collected_chl, collected_nuts, time_diff_mins,
         median_discrete_collected, discrete_sample_timediff_flag,
         min_bottle_collection_t, max_bottle_collection_t)

ds_qc_table <- min_ds %>% 
  filter(discrete_sample_timediff_flag != "") 

```

# CTD Data

```{r CTD}

qu39_ctd <- qu39_ctd %>% 
  mutate(month = month(date),
         depth = round(depth)) %>% # when I round it sometimes creates two rows for the same depth
  distinct_at(vars(date, depth), .keep_all = TRUE) # this removes the duplicated depths

```

# Join Discrete Samples and CTD Depths

```{r BFG}
class(discrete_samples$day)

qu39_ctd$date <- as_date(qu39_ctd$date)
bottle_file <- left_join(discrete_samples, qu39_ctd, by = c("date", "hakai_id", "work_area", "year", "site_id" = "station", "line_out_depth" = "depth"))
```


```{r bf qc}
#create minimal bottle file to QC

hakai_ids <- bottle_file %>% 
  select(hakai_id, bottom_dt, date, date_chl, date_nuts)

depth <- bottle_file %>%
  as_tibble() %>% 
  select("pressure", "start_depth", "bottom_depth", "line_out_depth", "original_bottom_depth",
         "target_depth", "pressure_transducer_depth", "pressure_transducer_depth_chl",
         "pressure_transducer_depth_nuts")

dates_qc <- bottle_file %>% 
  as_tibble() %>% 
  select(ctd_file_pk, ctd_cast_pk, ctd_data_pk, bottom_dt, original_bottom_dt, start_dt, original_start_dt, year, date, event_pk, date_chl, collected_chl, date_nuts, collected_nuts, collected_poms)  # No date_poms?
  
test_that("years are the same", {
  expect_equivalent(year(dates_qc$original_bottom_dt), year(dates_qc$date_chl))
  expect_equivalent(day(dates_qc$original_bottom_dt), day(dates_qc$date_chl))
})  


#TODO: Figure out why there's no date_poms  
#TODO: Convert all the dates to durations

min_bf <- bottle_file %>% 
  select(event_pk, line_out_depth, date, end_dt, temperature, collected_chl, collected_nuts, collected_poms)

ctd_time_match_qc <- min_bf %>% 
  mutate(median_discrete = median(c(collected_nuts, collected_chl)),
         ctd_time_diff = abs(difftime(end_dt, median_discrete, units = "mins")),
         ctd_time_flag = ifelse(ctd_time_diff > 180, "SVC", "")) %>% 
  filter(ctd_time_flag != "")
  
  

kable(ctd_time_match_qc, caption = "Table. Events for which CTD collection time was more than 180 minutes")

```
